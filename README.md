# UnbiasedDSA - Hemoglobin Prediction from Lip Images

A machine learning pipeline for estimating hemoglobin levels from lip images using computer vision and deep learning.

## Project Structure
```
UnbiasedDSA/
├── code/
│   ├── extractdata.py    # Data extraction from images
│   ├── dataset.py         # PyTorch dataset loader
│   ├── model.py           # Neural network architecture
│   ├── train.py           # Training script
│   ├── inference.py       # Prediction script
│   └── evaluate.py        # Model evaluation script
├── data/
│   ├── images/            # Input images (HEIC/JPG)
│   ├── labels.csv         # HgB labels
│   ├── meta.csv           # Image metadata
│   └── (Optional) combined_data.csv  # Only if generated by extractdata.py
├── weights/
│   └── best_model.pt      # Trained model weights
├── requirements.txt       # Python dependencies
├── model_card.md          # Model documentation
├── README.md              # This README file
└── report.pdf             # Technical report (2-3 pages)
```

## Setup Instructions

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Required Python Packages
```
torch>=2.0.0
torchvision>=0.15.0
pillow>=10.0.0
pillow-heif>=0.13.0
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0
albumentations>=1.3.0
opencv-python>=4.8.0
tqdm>=4.66.0
```

### 3. Prepare Your Data

**Step 1:** Place all lip images in data folder

**Step 2:** By default, `extractdata.py` reads from `../data/images`. Update the path only if your images are stored elsewhere.
```python
IMAGE_FOLDER = r"..\data\images"
```

**Step 3:** Run data extraction:
(This has been extracted already under the data folder but use extractdata.py for other datasets)
```bash
cd code
python extractdata.py
```

This generates:
- `data/labels.csv` - HgB values extracted from filenames
- `data/meta.csv` - Camera metadata (device, ISO, exposure, etc.)
- `data/combined_data.csv` - Complete dataset

## Model Training & Evaluation Pipeline

### Step 1: Train the Model
```bash
cd code
python train.py --images_dir ../data/images --labels_csv ../data/labels.csv --meta_csv ../data/meta.csv --output_dir ../data --batch_size 2 --epochs 40 --img_size 192 --use_metadata --backbone mobilenet_v3_small
```

**Training options:**
- `--epochs`: Number of training epochs (default: 50)
- `--batch_size`: Batch size (default: 2)
- `--lr`: Learning rate (default: 1e-4)
- `--images_dir`: Path to images (default: ../data/images)
- `--labels_csv`: Path to labels (default: ../data/labels.csv)
- `--output_dir`: Output directory for model (default: ../weights)

**Expected output:**
- Progress bars showing training/validation
- Epoch-by-epoch MAE metrics
- Best model saved to `weights/best_model.pt`

### Step 2: Run Inference

Generate predictions on images:
```bash
python inference.py --images ../data/images --weights ../weights/best_model.pt --meta ../data/meta.csv --out ../data/predictions.csv --img_size 192
```

Output format (`predictions.csv`):
```csv
image_id,predicted_hgb
HgB_10.7gdl_Individual01,10.8
HgB_12.0gdl_Individual02,11.9
...
```

### Step 3: Evaluate Model Performance

Run the evaluation script to assess your model:
```bash
python evaluate.py --labels_csv ../data/labels.csv --preds_csv ../data/predictions.csv
```

This will:
- Calculate Mean Absolute Error (MAE) and other metrics
- Display sample predictions vs ground truth
- Save detailed results to `evaluation_results.csv`
- Compare performance against competition target (0.8 g/dL MAE)

## Model Architecture

- **Backbone**: MobileNetV3-Small (pre-trained on ImageNet)
- **Head**: Fully connected regression layers with dropout
- **Loss**: Mean Absolute Error (MAE)
- **Optimizer**: AdamW with cosine annealing schedule
- **Input**: 192x192 RGB images
- **Model Size**: ~5 MB (meets edge-lite requirements)

## Data Augmentation

During training, a variety of image augmentations are applied to improve model generalization and robustness across lighting, skin tones, and camera conditions.

**Training augmentations include:**
- Random horizontal flips  
- Random brightness and contrast adjustments  
- Hue, saturation, and value (HSV) shifts  
- Gaussian noise addition  
- Random rotations and small affine transformations  
- ImageNet-style normalization (`mean=[0.485, 0.456, 0.406]`, `std=[0.229, 0.224, 0.225]`)

**Validation and inference transformations:**
- Center crop or resize to the target image size  
- ImageNet normalization only (no random augmentations)

These augmentations help the model learn invariance to lighting and positional changes, while preserving color fidelity — a critical factor for hemoglobin estimation tasks.


## File Format Specifications

**labels.csv:**
```csv
image_id,hgb
HgB_10.7gdl_Individual01,10.7
HgB_12.0gdl_Individual02_1,12.0
```

**meta.csv:**
```csv
image_id,device_id,device_brand,device_model,camera_type,iso_bucket,exposure_bucket,wb_bucket,ambient_light,distance_band,skin_tone_proxy,age_band,gender
HgB_10.7gdl_Individual01,Apple_iPhone_15_Pro_Max,Apple,iPhone 15 Pro Max,front,medium,fast,auto,indoor,close,unknown,unknown,unknown
```

## Metadata Fields

**Automatically extracted:**
- `device_brand` - Camera manufacturer (Apple, Samsung, etc.)
- `device_model` - Specific device model
- `camera_type` - front/back camera detection
- `iso_bucket` - ISO sensitivity (low/medium/high)
- `exposure_bucket` - Exposure time (fast/medium/slow)
- `wb_bucket` - White balance setting (auto/manual/daylight)

**Inferred from context:**
- `ambient_light` - Lighting condition (indoor assumed for medical setting)
- `distance_band` - Capture distance (close assumed for lip close-ups)

**Requires manual annotation:**
- `skin_tone_proxy` - Fitzpatrick scale (I-VI)
- `age_band` - Age categories
- `gender` - Gender categories


## Troubleshooting

### HEIC Files Won't Open
```bash
pip install pillow-heif
```

### OpenCV Installation Fails (Windows)
```bash
pip install opencv-python-headless
```


